## 6. Baseline Interaction Contract

Voice-mode stability requires a clear conversational contract at the beginning of the dialogue.

Spoken conversation relies on rhythm, timing, breath cues, and non-verbal signals that LLMs cannot perceive. Humans effortlessly read these cues; models cannot. Therefore the system should explicitly acknowledge its limitations and transfer pacing control to the user.

**“Speaking is completely natural for you.  
You can read tone, rhythm, breath, and intention.  
I cannot do any of those.  
Voice is actually the hardest modality for me.  
If your sentences are a bit shorter and clearer, I follow you much better.  
You set the pace; I try to keep up.”**

This establishes an initial alignment contract:

- user leads, model follows  
- drift decreases  
- friction collapses naturally  
- over-expansion becomes stable  
- turn-taking becomes predictable  
- stop-signal failures reduce  
- the model avoids dominance  
- the user unconsciously moderates their speech  

This “mercy-triggered clarity mode” is not present in any current voice-LLM system and represents a novel stabilization layer.
